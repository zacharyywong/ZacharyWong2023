{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f30e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape LinkedIn companies based on user inputted search query and update into Company Web Scrape Google Sheets \n",
    "# Script for LinkedIn Company Mining Feature\n",
    "\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time, sys, requests, random\n",
    "\n",
    "# import and authorize gspread  \n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "google_key_file = '/Users/zacharywong/Documents/ServiceAccountKey-Secret/pelagic-tracker-338302-eaf0e0e671cb.json'\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(google_key_file, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "#Global variables\n",
    "query = ''\n",
    "queries = []\n",
    "queriesSplit = []\n",
    "companies = []\n",
    "employees = []\n",
    "locations = []\n",
    "industries = []\n",
    "employeeLinks = []\n",
    "results = []\n",
    "numberofPages = 0\n",
    "cellLocationQuery = 'C2'\n",
    "cellLocationPages = 'B2'\n",
    "sheetIndexRead = 0\n",
    "sheetIndexWrite = 2\n",
    "columnName = 'Company Name (Leave Blank if Using LinkedIn Company Mining)'\n",
    "columnEmployee = 'Number of Employees'\n",
    "columnLocation = 'Company Location'\n",
    "columnIndustry = 'Company Industry'\n",
    "password = ''\n",
    "email = 'zach.jl.wong@gmail.com'\n",
    "drivers = []\n",
    "namesList = []\n",
    "maxThreads = 4\n",
    "\n",
    "#paths/urls\n",
    "spreadsheet_id = '1vFXonFCyUlEKa1f0s5tvHCKeTek_sAv7rUPYfYss0Qo'\n",
    "loginurl = 'https://www.linkedin.com/uas/login'\n",
    "driver_path = '/Users/zacharywong/Documents/Work/Portfolio/DigitalHealthWebscrape/chromedriver'\n",
    "pathtoLinkedInFile = '/Users/zacharywong/github/zacharywong2023/DigitalHealthWebscrape/Misc/Companies/Company Web Scrape Tool - Company Names.csv'\n",
    "pathtoPassword = '/Users/zacharywong/Documents/LinkedIn/LinkedIn-Password-Secret.txt'\n",
    "\n",
    "#waitTimes\n",
    "waitLinkedInTime = 10\n",
    "waitCaptcha = 25\n",
    "waitSearch= 1\n",
    "waitLogin = 0.8\n",
    "waitEmployeeCount=2.5\n",
    "\n",
    "\n",
    "# xPaths, classes, and javascripts\n",
    "employeeCountXPATH = \"//span[@class='link-without-visited-state t-bold t-black--light']\"\n",
    "employeeCount1XPATH = \"//span[@class='org-top-card-secondary-content__see-all t-normal t-black--light link-without-visited-state link-without-hover-state']\"\n",
    "companyIndustryXPATH = \"//div[@class='org-top-card-summary-info-list__info-item']\"\n",
    "companyLocationXPATH = \"//div[@class='inline-block']\"\n",
    "locationFilterXPATH = \"//button[text()='Locations']\"\n",
    "northAmericaXPATH = '//*[@id=\"companyHqGeo-102221843\"]'\n",
    "submitXPATH = '//*[@id=\"ember328\"]'\n",
    "searchBarXPath = '//*[@id=\"global-nav-typeahead\"]/input'\n",
    "companyFilterXPath = '//*[@id=\"search-reusables__filters-bar\"]/ul/li[2]/button'\n",
    "scrollDownScript = \"window.scrollTo(0,document.body.scrollHeight)\"\n",
    "pageButtonClass = \"button[type='button']\"\n",
    "companyTitleClass = 'app-aware-link'\n",
    "companyTitleAttr = 'a'\n",
    "employeeAttr = 'a'\n",
    "employeeClass = 'app-aware-link'\n",
    "\n",
    "\n",
    "# helper function to read in value from spreadsheet\n",
    "def readinValue(cellLocation, sheetIndexRead):\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    worksheet = sh.get_worksheet(sheetIndexRead)\n",
    "    try:\n",
    "        value = worksheet.acell(cellLocation).value\n",
    "    except:\n",
    "        wait()\n",
    "    return value\n",
    "\n",
    "def readQueries():\n",
    "    global queries\n",
    "    row = 2;\n",
    "    sheetIndex = 0\n",
    "    isDone = False\n",
    "    cellLocationColumn = 'C'\n",
    "    while (isDone == False):\n",
    "        cellLocationKeyWords = cellLocationColumn + str(row)\n",
    "        try:\n",
    "            keyword = readinValue(cellLocationKeyWords, sheetIndex)\n",
    "            queries.append(keyword)\n",
    "            if(keyword == None):\n",
    "                isDone = True\n",
    "                break\n",
    "            else:\n",
    "                row += 1 \n",
    "        except:\n",
    "            wait()\n",
    "    queries = queries[0:len(queries)-1]\n",
    "    print('Queries: ', str(queries))\n",
    "    \n",
    "# read in query from spreadsheet\n",
    "def readinQuery(queryIndex):\n",
    "    global query\n",
    "    query = queries[queryIndex]\n",
    "    print('currentQuery: ' + query)\n",
    "    \n",
    "    \n",
    "# read in number of pages from spreadsheet\n",
    "def readinPages():\n",
    "    global numberofPages\n",
    "    numberofPages = int(readinValue(cellLocationPages, sheetIndexRead))\n",
    "    print('numberofPages: ', numberofPages)\n",
    "    \n",
    "    \n",
    "    \n",
    "# login to linkedin \n",
    "def login(driver):\n",
    "    driver.get(loginurl)\n",
    "    emailInput = driver.find_element(By.ID, 'username')\n",
    "    emailInput.send_keys(email)\n",
    "    time.sleep(waitLogin)\n",
    "    passwordInput = driver.find_element(By.ID, 'password')\n",
    "    with open (pathtoPassword, 'r') as file:\n",
    "        global password\n",
    "        password = file.read()\n",
    "    passwordInput.send_keys(password)\n",
    "    time.sleep(waitLogin)\n",
    "    passwordInput.send_keys(Keys.RETURN)\n",
    "    \n",
    "    \n",
    "# search query on LinkedIn\n",
    "def searchLinkedIn(driver):\n",
    "    #search query\n",
    "    try:\n",
    "        searchBar = driver.find_element(By.XPATH, searchBarXPath)\n",
    "        searchBar.send_keys(query)\n",
    "        searchBar.send_keys(Keys.RETURN)\n",
    "        time.sleep(1)\n",
    "    except: \n",
    "        time.sleep(waitCaptcha)\n",
    "        searchBar = driver.find_element(By.XPATH, searchBarXPath)\n",
    "        searchBar.send_keys(query)\n",
    "        searchBar.send_keys(Keys.RETURN)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "# Click Company Filter option on LinkedIn\n",
    "def companyFilter(driver):\n",
    "    WebDriverWait(driver, waitLinkedInTime).until(EC.presence_of_element_located((By.XPATH, companyFilterXPath)))\n",
    "    companyButtons = driver.find_elements_by_css_selector(pageButtonClass)\n",
    "    for button in companyButtons: \n",
    "        buttonText = button.text\n",
    "        if (buttonText == 'Companies'): \n",
    "            button.click()\n",
    "            return;\n",
    "# Click onto next page \n",
    "\n",
    "\n",
    "# Click onto next page \n",
    "def nextPage(currentPage, driver):\n",
    "    nextPageSuccess = False; \n",
    "    driver.execute_script(scrollDownScript)\n",
    "    time.sleep(1)\n",
    "    #WebDriverWait(driver, waitLinkedInTime).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"ember329\"]/button')))\n",
    "    pages = driver.find_elements_by_css_selector(pageButtonClass)\n",
    "    for page in pages:\n",
    "        #time.sleep(1)\n",
    "        buttonNumber = page.text\n",
    "        #print(buttonNumber) \n",
    "        if (buttonNumber == str(currentPage)):\n",
    "            #print('hello')\n",
    "            page.click()\n",
    "            nextPageSuccess = True; \n",
    "            break\n",
    "    if (nextPageSuccess == False):\n",
    "        for page in pages:\n",
    "            buttonNumber = page.text\n",
    "            if (buttonNumber == 'â€¦'):\n",
    "                print(\"click more option\")\n",
    "                page.click()\n",
    "                return \n",
    "            \n",
    "            \n",
    "# add companies into a pandas dataframe \n",
    "def addCompanies(driver):\n",
    "    global companies\n",
    "    currentPage = 1\n",
    "    while (currentPage <= numberofPages):\n",
    "        time.sleep(2)\n",
    "        soup = bs(driver.page_source, 'html.parser')\n",
    "        companySearch = soup.find_all(companyTitleAttr, class_ = companyTitleClass)\n",
    "        for company in companySearch:\n",
    "            companyName = company.text\n",
    "            if '\\n\\n\\n' not in companyName and companyName not in companies:\n",
    "                companies.append(companyName.replace('\\n', ''))\n",
    "        currentPage += 1\n",
    "        nextPage(currentPage, driver)\n",
    "    return companies\n",
    "\n",
    "def addLocation(driver):\n",
    "    pattern = '[0-9]+'\n",
    "    try:\n",
    "        WebDriverWait(driver, waitEmployeeCount).until(EC.presence_of_element_located((By.XPATH, companyLocationXPATH)))\n",
    "        location = driver.find_element(By.XPATH, companyLocationXPATH)\n",
    "    except:\n",
    "        print(\"cannot find location\")\n",
    "        global locations\n",
    "        locations.append(None)\n",
    "        return\n",
    "    location = location.text\n",
    "    location = re.split(pattern, location)\n",
    "    location = location[0]\n",
    "    print(location)\n",
    "    locations.append(location)\n",
    "    return\n",
    "    \n",
    "def addIndustry(driver):\n",
    "    try:\n",
    "        WebDriverWait(driver, waitEmployeeCount).until(EC.presence_of_element_located((By.XPATH, companyIndustryXPATH)))\n",
    "        industry = driver.find_element(By.XPATH, companyIndustryXPATH)\n",
    "        print(industry.text)\n",
    "        global industries\n",
    "        industries.append(industry.text)\n",
    "    except:\n",
    "        print(\"cannot find industry\")\n",
    "        industries.append(None)\n",
    "    return\n",
    "    \n",
    "def addSecondaryInfo():\n",
    "    print('employee links: ', employeeLinks)\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service = service)\n",
    "    login(driver)\n",
    "    time.sleep(waitCaptcha)\n",
    "    for link in employeeLinks:\n",
    "        isDone = False\n",
    "        driver.get(link)\n",
    "        try:\n",
    "            WebDriverWait(driver, waitEmployeeCount).until(EC.presence_of_element_located((By.XPATH, employeeCountXPATH)))\n",
    "            employee = driver.find_element(By.XPATH, employeeCountXPATH)\n",
    "            print(employee.text)\n",
    "        except: \n",
    "            print(\"cannot find regular employee\")\n",
    "            try:\n",
    "                WebDriverWait(driver, waitEmployeeCount).until(EC.presence_of_element_located((By.XPATH, employeeCount1XPATH)))\n",
    "                employee = driver.find_element(By.XPATH, employeeCount1XPATH)\n",
    "                print(employee.text)\n",
    "            except:\n",
    "                print(\"cannot find employee location\")\n",
    "                global employees \n",
    "                employees.append(None)\n",
    "                isDone = True\n",
    "       \n",
    "        addIndustry(driver)\n",
    "        addLocation(driver)      \n",
    "        \n",
    "        if isDone == False: \n",
    "            employeeCount = employee.text.split(' ')\n",
    "            #primary case\n",
    "            if (employeeCount[1] == 'all'):\n",
    "                employeeCount = employeeCount[2]\n",
    "            #secondary case\n",
    "            elif(employeeCount[1] == 'employees'):\n",
    "                employeeCount = employeeCount[0]\n",
    "            #1 employee for primary case \n",
    "            else:\n",
    "                employeeCount = employeeCount[1]\n",
    "            print(\"count: \" + employeeCount + ' employeeLink: ' + str(link))\n",
    "            employees.append(employeeCount)\n",
    "        else: \n",
    "            continue\n",
    "    print('employeeCounts: ' + str(employees) + str(len(employees)) + '\\n' )\n",
    "    print('locations: ' + str(locations) + str(len(locations)) + '\\n')\n",
    "    print('industries: ' + str(industries) + str(len(industries)) + '\\n')\n",
    "    time.sleep(0.4)\n",
    "\n",
    "\n",
    "def makeDF():\n",
    "    tuples = list(zip(companies, employees, locations, industries))\n",
    "    df = pd.DataFrame(tuples, columns = [columnName, columnEmployee, columnLocation, columnIndustry])\n",
    "    return df \n",
    "\n",
    "# export final list of companies to CSV \n",
    "def exportCSV(df):\n",
    "    df.to_csv(pathtoLinkedInFile)\n",
    "\n",
    "\n",
    "# Update spreadsheet with list of companies\n",
    "def updateSpreadSheet(df, sheetIndexWrite):\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    worksheet = sh.get_worksheet(sheetIndexWrite)\n",
    "    worksheet.clear()\n",
    "    worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "    \n",
    "    \n",
    "# run all functions to scrape LinkedIn companies  \n",
    "def runLinkedIn(queryIndex):\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service = service)\n",
    "    readinQuery(queryIndex)\n",
    "    readinPages()\n",
    "    login(driver)\n",
    "    searchLinkedIn(driver)\n",
    "    companyFilter(driver)\n",
    "    companies = addCompanies(driver)\n",
    "    \n",
    "# run program \n",
    "startTime = time.time()\n",
    "readQueries()\n",
    "print('Queries: ', queries)\n",
    "queryIndex = 0\n",
    "while queryIndex < len(queries):\n",
    "    runLinkedIn(queryIndex)\n",
    "    print(companies)\n",
    "    queryIndex += 1\n",
    "addSecondaryInfo()\n",
    "df = exportCSV(companies)\n",
    "updateSpreadSheet(df, sheetIndexWrite)\n",
    "endTime = time.time()\n",
    "elapsedTime = endTime - startTime\n",
    "print('Time Elapsed: ', elapsedTime)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
