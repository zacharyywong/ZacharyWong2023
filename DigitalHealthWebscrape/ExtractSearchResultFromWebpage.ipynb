{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extracts the title, link, and short description of search results on Google \n",
    "\n",
    "#import all libraries\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be90ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for keyword, number of pages to scrape, and google baseURL\n",
    "# only want top result so only search for 1 result \n",
    "nPages = 1\n",
    "maxResult = 1\n",
    "googleurl = 'https://www.google.com/'\n",
    "baseurl = 'https://www.babylonhealth.com/en-us'\n",
    "query = \"site: \" + baseurl\n",
    "websiteName = 'babylon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97863380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Driver [/Users/zacharywong/.wdm/drivers/chromedriver/mac64/98.0.4758.102/chromedriver] found in cache\n",
      "/var/folders/gl/jgk7f2w528qgjggck6glqp200000gn/T/ipykernel_65392/2887605795.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "# Access chromedriver and determine path \n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "pathToFile = '/Users/zacharywong/github/zacharywong2023/DigitalHealthWebscrape/Deliverables/'\n",
    "driver.get(googleurl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae635f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the keyword you want to search for\n",
    "# we find the search bar using it's name attribute value\n",
    "searchBar = driver.find_element_by_name('q')\n",
    "# first we send our keyword to the search bar followed by the enter # key\n",
    "searchBar.send_keys(query)\n",
    "searchBar.send_keys('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dictionaries with key/value pairs: title, link, text\n",
    "# Contains all information for all search results \n",
    "pageInfo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83469721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract links from 1 page of results\n",
    "def extractLink(soup):\n",
    "    links = []\n",
    "    searchLinks = soup.find_all('div', class_ = 'yuRUbf')\n",
    "    for h in searchLinks:\n",
    "        link = h.a.get('href')\n",
    "        links.append(link)\n",
    "    return links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9762b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract texts from 1 page of results\n",
    "def extractText(soup):\n",
    "    texts = []\n",
    "    searchText = soup.find_all('div', class_='VwiC3b yXK7lf MUxGbd yDYNvb lyLwlc lEBKkf')\n",
    "    for h in searchText:\n",
    "        fullText = h.text\n",
    "        try:\n",
    "            splitText = fullText.split('â€” ', 1)\n",
    "            text = splitText[1]\n",
    "            texts.append(text);\n",
    "        except:\n",
    "            texts.append(fullText)\n",
    "    return texts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82491fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to extract titles from 1 page of results\n",
    "def extractTitle(soup):\n",
    "    titles = [] \n",
    "    searchTitles = soup.find_all('h3', class_='LC20lb MBeuO DKV0Md')\n",
    "    for h in searchTitles:\n",
    "        titles.append(h.text)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad724de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to add 1 page of results to pageInfo list\n",
    "def addToPageInfo(titles, links, texts):\n",
    "    index = 0;\n",
    "    while (index < maxResult):\n",
    "        # create new dictionary of each search results' title, link, and text\n",
    "        pageInfo.append({\"Title\": titles[index], \"Link\": links[index], \"About\": texts[index]})\n",
    "        index+=1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251606e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture links, header, and text\n",
    "#pageInfo is a list of dictionaries for each page with keys/value pairs: header, link, text\n",
    "# extract and load each page of results to pageInfo \n",
    "\n",
    "for page in range(1, nPages+1):\n",
    "    #driver.get(url)\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    links = extractLink(soup);\n",
    "    texts = extractText(soup);\n",
    "    titles = extractTitle(soup);\n",
    "    addToPageInfo(titles, links, texts)\n",
    "    \n",
    "pageInfo \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78485490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pageInfo to pandas dataframe and export as csv \n",
    "df = pd.DataFrame(pageInfo)\n",
    "df.to_csv(pathToFile + 'Info_' + websiteName + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.google.com/search?q=site%3A+https%3A%2F%2Fwww.babylonhealth.com%2Fen-us&oq=site&aqs=chrome.0.69i59j69i57j0i433i512l2j46i199i465i512j69i61j69i60j69i61.710j0j7&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.google.com/search?q=site%3A+https%3A%2F%2Fwww.concertai.com%2Fpredictivepatient%2F&oq=site%3A+https%3A%2F%2Fwww.concertai.com%2Fpredictivepatient%2F&aqs=chrome..69i57j69i58.1453j0j7&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65104f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
